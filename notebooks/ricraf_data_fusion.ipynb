{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Road Infrastructure Climate Risk Assessment Framework\n",
    "## RICRAF Road and Climate Data Fusion\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook processes raw open-source road and climate datasets for the **Road Infrastructure Climate Risk Assessment Framework (RICRAF)**. It fuses multiple road datasets (traffic volume, road width, and pavement condition) and integrates them with climate hazard data (e.g. extreme rainfall, temperature, drought). The output is a unified GeoJSON dataset adhering to FAIR (Findable, Accessible, Interoperable, Reusable) principles for reproducibility in academic and applied settings.\n",
    "\n",
    "The workflow is divided into stages:\n",
    "1. **Fuse Road Datasets**: Merge traffic volume, road width, and pavement condition data.\n",
    "2. **Fuse Road and Climate Datasets**: Spatially join the fused road data with climate variables.\n",
    "3. **Final Data Cleaning**: Handle missing values, compute derived features, and ensure data quality.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Input Data Sources**:\n",
    "- Road data: DataVic (traffic volume, pavement condition, road width).\n",
    "- Climate data: Australian Bureau of Meteorology (heatwaves, rainfall, etc.), for various Global Warming Levels (GWL: current 1.2°C, 1.5°C, 2.0°C, 3.0°C).\n",
    "\n",
    "- **Output**:\n",
    "- Fused GeoJSON dataset (`gdf_road_clim_cln.geojson`).\n",
    "- Interim files in `../data/interim/` for debugging and reproducibility.\n",
    "\n",
    "- **Reproducibility**: All steps are scripted with modular functions from `src/`.\n",
    "\n",
    "- **Dependencies**: Listed in `requirements.txt` (e.g., geopandas==1.0.1).\n",
    "\n",
    "### Usage Instructions\n",
    "1. Install dependencies: `pip install -r requirements.txt`.\n",
    "2. Run cells sequentially.\n",
    "3. Outputs are saved to `data/interim/` and `data/processed/`.\n",
    "\n",
    "For full documentation, see the Data Paper (submitted to *Earth System Science Data*).\n",
    "\n",
    "**Notes:**\n",
    "- All spatial operations use EPSG:3111 (GDA94 / Vicgrid) for Victoria, Australia. Adapt CRS for other regions.\n",
    "- This notebook emphasises reproducibility: Use virtual environments and document all steps.\n",
    "- For large datasets, ensure sufficient memory (e.g. 16GB+ RAM). Consider Dask for parallel processing if scaling.\n",
    "    - Large files are linked via DOI; raw data is not stored in the repository.\n",
    "- Citation: If using this code or data, cite the associated papers and this repository (DOI via Zenodo).\n",
    "- Optional EDA: Uncomment matplotlib imports for visual inspections (e.g. histograms of fused variables).\n",
    "\n",
    "**Dependencies:**\n",
    "- Python 3.12+\n",
    "- geopandas==1.0.1\n",
    "- pandas==2.2.3\n",
    "- shapely==2.0.6\n",
    "- numpy==2.1.3\n",
    "Install via `requirements.txt` or uncomment the installation cells below."
   ],
   "id": "944249a50945be9b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Infrastructure Climate Risk Assessment Framework\n",
    "## RICRAF Road and Climate Data Fusion\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook processes raw open-source raw road and climate datasets for the **Road Infrastructure Climate Risk Assessment Framework (RICRAF)**. It fuses multiple road datasets (traffic volume, road width, and pavement condition) and integrates them with climate hazard data (e.g. extreme rainfall, temperature, drought). The output is a unified GeoJSON dataset adhering to FAIR (Findable, Accessible, Interoperable, Reusable) principles for reproducibility in academic and applied settings.\n",
    "\n",
    "The workflow is divided into stages:\n",
    "1. **Fuse Road Datasets**: Merge traffic volume, road width, and pavement condition data.\n",
    "2. **Fuse Road and Climate Datasets**: Spatially join the fused road data with climate variables.\n",
    "3. **Final Data Cleaning**: Handle missing values, compute derived features, and ensure data quality.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Input Data Sources**:\n",
    "  - Road data: DataVic (traffic volume, pavement condition, road width).\n",
    "  - Climate data: Australian Climate Service (heatwaves, rainfall, etc.), for various Global Warming Levels (GWL: current 1.2°C, 1.5°C, 2.0°C, 3.0°C).\n",
    "\n",
    "- **Output**:\n",
    "  - Fused GeoJSON dataset (`gdf_road_clim_cln.geojson`).\n",
    "  - Interim files in `../data/interim/` for debugging and reproducibility.\n",
    "\n",
    "- **Reproducibility**: All steps are scripted with modular functions from `src/`.\n",
    "\n",
    "- **Dependencies**: Listed in `requirements.txt` (e.g. geopandas==0.14.4).\n",
    "\n",
    "\n",
    "### Usage Instructions\n",
    "1. Install dependencies: `pip install -r requirements.txt`.\n",
    "2. Run cells sequentially.\n",
    "3. Outputs are saved to `data/interim/` and `data/processed/`.\n",
    "\n",
    "For full documentation, see the [Data Paper](link-to-paper) (submitted to *Earth System Science Data*).\n",
    "\n",
    "\n",
    "**Notes:**\n",
    "- All spatial operations use EPSG:3111 (GDA94 / Vicgrid) for Victoria, Australia. Adapt CRS for other regions.\n",
    "- This notebook emphasises reproducibility: Use virtual environments and document all steps.\n",
    "- For large datasets, ensure sufficient memory (e.g. 16GB+ RAM).\n",
    "- Large files are linked via DOI; raw data is not stored in the repository.\n",
    "- Citation: If using this code or data, cite the associated papers and this repository (DOI via Zenodo).\n",
    "\n",
    "\n",
    "**Dependencies:**\n",
    "- Python 3.12+\n",
    "- geopandas==1.0.1\n",
    "- pandas==2.2.3\n",
    "- shapely==2.0.6\n",
    "- numpy==2.1.3\n",
    "\n",
    "Install via `requirements.txt` or uncomment the installation cells below.\n"
   ],
   "id": "947cae662df1170a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:36:10.658666Z",
     "start_time": "2025-10-19T14:36:10.655563Z"
    }
   },
   "source": [
    "# Uncomment to install dependencies if needed\n",
    "# %pip install pandas==2.2.3\n",
    "# %pip install -U numpy==2.1.3\n",
    "# %conda install geopandas==1.0.1\n",
    "# %pip install shapely==2.0.6\n",
    "# %pip install loguru"
   ],
   "id": "a981757f412c1882",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Fuse Road Datasets\n",
    "\n",
    "This stage loads the following three raw road datasets, cleans them (removing duplicates and invalid geometries), and fuses them using spatial and attribute matching:\n",
    "- Traffic Volume (from DataVic).\n",
    "- Road Width and Number of Lanes (from DataVic).\n",
    "- Pavement Condition (from DataVic).\n",
    "The fused road dataset serves as the base for climate integration.\n",
    "\n",
    "**Key Steps:**\n",
    "- Load and reproject datasets to Vicgrid (EPSG:3111).\n",
    "- Clean duplicates and null geometries.\n",
    "- Fuse traffic volume with road width/lanes and pavement condition.\n",
    "- Output interim fused datasets for verification.\n",
    "\n",
    "Data is cleaned (duplicates removed, NoneType geometries handled), and fused using spatial and attribute matching. Outputs are saved in `../data/interim/` for traceability.\n",
    "\n"
   ],
   "id": "1b0fb3526c388ab5"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:48:51.895275Z",
     "start_time": "2025-10-19T14:36:11.417062Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "\n",
    "# Add project root to path for custom module imports\n",
    "sys.path.append('..')\n",
    "from src.ricraf_data_fusion import fuse_road_data  # Custom fusion function\n",
    "\n",
    "# Define parameters\n",
    "now = datetime.now()\n",
    "data_dir = \"../data/interim\"\n",
    "output_dir1 = os.path.join(data_dir, f\"ricraf_fuse_data_s1p1\")\n",
    "os.makedirs(output_dir1, exist_ok=True)\n",
    "output_dir2 = os.path.join(data_dir, f\"ricraf_fuse_data_s1p2\")\n",
    "os.makedirs(output_dir2, exist_ok=True)\n",
    "gda94_vg = 3111  # EPSG code for GDA94 / Vicgrid\n",
    "\n",
    "# Columns to retain\n",
    "cols_vol = [\n",
    "    'OBJECTID_1', 'HMGNS_LN_1', 'LGA_SHORT_', 'RGN_LONG_N', 'ROAD_NBR', 'DECLARED_R', 'LOCAL_ROAD',\n",
    "    'RMA_CLSFCN', 'SRNS_CD', 'FLOW', 'ALLVEHS_AA', 'TRUCKS_AAD', 'LABEL', 'geometry',\n",
    "]\n",
    "cols_lwd = [\n",
    "    'OBJECTID', 'ROAD_NUMBE', 'ROAD_NAME', 'DIRECTION', 'SURFACE_TY', 'ELEMENTS',\n",
    "    'SEAL_WIDTH', 'geometry',\n",
    "]\n",
    "cols_pav = [\n",
    "    'OBJECTID', 'Classified', 'Name_Part', 'Road_Type_', 'Direction', 'Region', 'RMA_Class',\n",
    "    'Federal_Ro', 'Surface_Ty', 'Roughness_', 'HATI_Categ', 'Texture__L', 'Texture__B',\n",
    "    'Rutting_Ca', 'Cracking_C', 'geometry',\n",
    "]\n",
    "\n",
    "# Load and reproject datasets with error handling\n",
    "try:\n",
    "    gdf_vol = gpd.read_file(\"../data/raw/road_data/Traffic_Volume.shp\").to_crs(epsg=gda94_vg)[cols_vol]\n",
    "    gdf_lwd = gpd.read_file(\"../data/raw/road_data/Road_Width_and_Number_of_Lanes.shp\").to_crs(epsg=gda94_vg)[cols_lwd]\n",
    "    gdf_pav = gpd.read_file(\"../data/raw/road_data/Pavement_Condition_Data.shp\").to_crs(epsg=gda94_vg)[cols_pav]\n",
    "    print(f\"Raw gdf_vol records: {len(gdf_vol)}\")\n",
    "    print(f\"Raw gdf_lwd records: {len(gdf_lwd)}\")\n",
    "    print(f\"Raw gdf_pav records: {len(gdf_pav)}\")\n",
    "except FileNotFoundError as e:\n",
    "    raise FileNotFoundError(f\"Raw data file not found: {e}\")\n",
    "\n",
    "# Clean datasets: Remove duplicates\n",
    "gdf_vol_cln = gdf_vol.drop_duplicates(subset=[\"HMGNS_LN_1\", \"FLOW\", \"LABEL\", \"geometry\"], keep='first')\n",
    "gdf_lwd_cln = gdf_lwd.drop_duplicates(subset=[\"ROAD_NAME\", \"DIRECTION\", \"ELEMENTS\", \"SURFACE_TY\", \"geometry\"], keep='first')\n",
    "gdf_pav_cln = gdf_pav.drop_duplicates(subset=[\"Name_Part\", \"Road_Type_\", \"Direction\", \"Surface_Ty\",  \"geometry\"], keep='first')\n",
    "print(f\"Removed duplicates - gdf_vol records: {len(gdf_vol_cln)}\")\n",
    "print(f\"Removed duplicates - gdf_lwd records: {len(gdf_lwd_cln)}\")\n",
    "print(f\"Removed duplicates - gdf_pav records: {len(gdf_pav_cln)}\")\n",
    "\n",
    "# Remove invalid (NoneType) geometries\n",
    "gdf_vol_cln = gdf_vol_cln[gdf_vol_cln['geometry'].notna()]\n",
    "gdf_lwd_cln = gdf_lwd_cln[gdf_lwd_cln['geometry'].notna()]\n",
    "gdf_pav_cln = gdf_pav_cln[gdf_pav_cln['geometry'].notna()]\n",
    "print(f\"Cleaned gdf_vol records (removed NoneType geometries): {len(gdf_vol_cln)}\")\n",
    "print(f\"Cleaned gdf_lwd records (removed NoneType geometries): {len(gdf_lwd_cln)}\")\n",
    "print(f\"Cleaned gdf_pav records (removed NoneType geometries): {len(gdf_pav_cln)}\")\n",
    "\n",
    "# Rename OBJECTID columns to avoid conflicts\n",
    "gdf_lwd_cln = gdf_lwd_cln.rename(columns={\"OBJECTID\": \"OBJECTID_LWD\"})\n",
    "gdf_pav_cln = gdf_pav_cln.rename(columns={\"OBJECTID\": \"OBJECTID_PAV\"})\n",
    "\n",
    "# Create ROAD_NAME in pavement data for matching\n",
    "gdf_pav_cln[\"ROAD_NAME\"] = gdf_pav_cln[\"Name_Part\"] + \" \" + gdf_pav_cln[\"Road_Type_\"]\n",
    "\n",
    "# Verify and clean key columns (drop rows with nulls in matching columns)\n",
    "main_cols = [\"ROAD_NBR\", \"HMGNS_LN_1\", \"DECLARED_R\"]\n",
    "supp_cols1 = [\"ROAD_NUMBE\", \"ROAD_NAME\"]\n",
    "supp_cols2 = [\"Classified\", \"ROAD_NAME\"]\n",
    "gdf_vol_cln = gdf_vol_cln.dropna(subset=main_cols)\n",
    "gdf_lwd_cln = gdf_lwd_cln.dropna(subset=supp_cols1)\n",
    "gdf_pav_cln = gdf_pav_cln.dropna(subset=supp_cols2)\n",
    "print(f\"Cleaned gdf_vol records (removed nulls in key columns): {len(gdf_vol_cln)}\")\n",
    "print(f\"Cleaned gdf_lwd records (removed nulls in key columns): {len(gdf_lwd_cln)}\")\n",
    "print(f\"Cleaned gdf_pav records (removed nulls in key columns): {len(gdf_pav_cln)}\")\n",
    "\n",
    "# Validate column presence and null counts\n",
    "for col in main_cols:\n",
    "    if col not in gdf_vol_cln.columns:\n",
    "        raise ValueError(f\"Column '{col}' not found in gdf_vol\")\n",
    "    print(f\"gdf_vol['{col}'] null count: {gdf_vol_cln[col].isna().sum()}\")\n",
    "for col in supp_cols1:\n",
    "    if col not in gdf_lwd_cln.columns:\n",
    "        raise ValueError(f\"Column '{col}' not found in gdf_lwd\")\n",
    "    print(f\"gdf_lwd['{col}'] null count: {gdf_lwd_cln[col].isna().sum()}\")\n",
    "for col in supp_cols2:\n",
    "    if col not in gdf_pav_cln.columns:\n",
    "        raise ValueError(f\"Column '{col}' not found in gdf_pav\")\n",
    "    print(f\"gdf_pav['{col}'] null count: {gdf_pav_cln[col].isna().sum()}\")\n",
    "\n",
    "# Step 1: Fuse Traffic Volume and Road Width/Lanes\n",
    "gdf_vol_rd_cfg, gdf_supp_matched, gdf_supp_unmatched, gdf_issues, gdf_main_split_rows, gdf_supp_split_rows = fuse_road_data(\n",
    "    gdf_main=gdf_vol_cln,\n",
    "    gdf_supp=gdf_lwd_cln,\n",
    "    output_dir=output_dir1,\n",
    "    main_road_num_col=\"ROAD_NBR\",\n",
    "    supp_road_num_col=\"ROAD_NUMBE\",\n",
    "    main_road_name_cols=[\"HMGNS_LN_1\", \"DECLARED_R\"],\n",
    "    supp_road_name_col=\"ROAD_NAME\",\n",
    "    verification_id_col=\"OBJECTID_LWD\",\n",
    "    log_level_console=\"WARNING\",\n",
    "    log_level_file=\"DEBUG\",\n",
    "    output_format=\"GeoJSON\",\n",
    "    output_name=\"gdf_vol_rd_cfg\"\n",
    ")\n",
    "\n",
    "# Validate Step 1 Outputs\n",
    "print(f\"Total gdf_vol_cln rows: {len(gdf_vol_cln)}\")\n",
    "print(f\"Matched records: {len(gdf_vol_rd_cfg)}\")\n",
    "print(f\"Supplementary matched: {len(gdf_supp_matched)}\")\n",
    "print(f\"Supplementary unmatched: {len(gdf_supp_unmatched)}\")\n",
    "print(f\"Issues found: {len(gdf_issues)}\")\n",
    "\n",
    "# Step 2: Fuse with Pavement Condition\n",
    "gdf_vol_rd_pav, gdf_supp_matched2, gdf_supp_unmatched2, gdf_issues2, gdf_main_split_rows2, gdf_supp_split_rows2 = fuse_road_data(\n",
    "    gdf_main=gdf_vol_rd_cfg,\n",
    "    gdf_supp=gdf_pav_cln,\n",
    "    output_dir=output_dir2,\n",
    "    main_road_num_col=\"ROAD_NBR\",\n",
    "    supp_road_num_col=\"Classified\",\n",
    "    main_road_name_cols=[\"HMGNS_LN_1\", \"DECLARED_R\"],\n",
    "    supp_road_name_col=\"ROAD_NAME\",\n",
    "    verification_id_col=\"OBJECTID_PAV\",\n",
    "    log_level_console=\"WARNING\",\n",
    "    log_level_file=\"DEBUG\",\n",
    "    output_format=\"GeoJSON\",\n",
    "    output_name=\"gdf_vol_rd_pav\"\n",
    ")\n",
    "\n",
    "# Validate Step 2 Outputs\n",
    "print(f\"Total gdf_vol_rd_cfg rows: {len(gdf_vol_rd_cfg)}\")\n",
    "print(f\"Matched records: {len(gdf_vol_rd_pav)}\")\n",
    "print(f\"Supplementary matched: {len(gdf_supp_matched2)}\")\n",
    "print(f\"Supplementary unmatched: {len(gdf_supp_unmatched2)}\")\n",
    "print(f\"Issues found: {len(gdf_issues2)}\")"
   ],
   "id": "6a9da652cf34dffd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw gdf_vol records: 14674\n",
      "Raw gdf_lwd records: 74711\n",
      "Raw gdf_pav records: 238837\n",
      "Removed duplicates - gdf_vol records: 14647\n",
      "Removed duplicates - gdf_lwd records: 74710\n",
      "Removed duplicates - gdf_pav records: 238722\n",
      "Cleaned gdf_vol records (removed NoneType geometries): 14647\n",
      "Cleaned gdf_lwd records (removed NoneType geometries): 74691\n",
      "Cleaned gdf_pav records (removed NoneType geometries): 238721\n",
      "Cleaned gdf_vol records (removed nulls in key columns): 14639\n",
      "Cleaned gdf_lwd records (removed nulls in key columns): 74691\n",
      "Cleaned gdf_pav records (removed nulls in key columns): 238668\n",
      "gdf_vol['ROAD_NBR'] null count: 0\n",
      "gdf_vol['HMGNS_LN_1'] null count: 0\n",
      "gdf_vol['DECLARED_R'] null count: 0\n",
      "gdf_lwd['ROAD_NUMBE'] null count: 0\n",
      "gdf_lwd['ROAD_NAME'] null count: 0\n",
      "gdf_pav['Classified'] null count: 0\n",
      "gdf_pav['ROAD_NAME'] null count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-10-20 00:37:49.649\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36msrc.ricraf_data_fusion\u001B[0m:\u001B[36mfuse_road_data\u001B[0m:\u001B[36m440\u001B[0m - \u001B[33m\u001B[1mFound 1458 records with mismatched Travel_Dir or Part_Rd_Name/Part_DRd_Name\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gdf_vol_cln rows: 14639\n",
      "Matched records: 14647\n",
      "Supplementary matched: 70202\n",
      "Supplementary unmatched: 4490\n",
      "Issues found: 1458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-10-20 00:47:40.135\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36msrc.ricraf_data_fusion\u001B[0m:\u001B[36mfuse_road_data\u001B[0m:\u001B[36m440\u001B[0m - \u001B[33m\u001B[1mFound 2171 records with mismatched Travel_Dir or Part_Rd_Name/Part_DRd_Name\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gdf_vol_rd_cfg rows: 14647\n",
      "Matched records: 14647\n",
      "Supplementary matched: 428660\n",
      "Supplementary unmatched: 46182\n",
      "Issues found: 2171\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Fuse Road and Climate Datasets\n",
    "\n",
    "This stage spatially joins the fused road data with climate datasets (e.g. rainfall, temperature) from the Australian Climate Service. Climate values are aggregated (mean) over intersecting road segments. Missing values are handled via nearest-neighbor interpolation.\n",
    "\n",
    "The result is a comprehensive geospatial dataset ready for climate risk model development and assessment.\n",
    "\n",
    "\n",
    "**Key Steps:**\n",
    "- Define climate variables and target columns.\n",
    "- Perform spatial joins and handle nulls.\n",
    "- Output the road-climate fused dataset and save in `../data/interim/` for traceability.\n"
   ],
   "id": "4a9b623b3034af2a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:49:20.402630Z",
     "start_time": "2025-10-19T14:48:52.039017Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path for custom module imports\n",
    "sys.path.append('..')\n",
    "from src.ricraf_data_fusion import merge_road_climate  # Custom merge function\n",
    "\n",
    "# CRS definitions\n",
    "crs_wgs84 = 4326\n",
    "crs_vic = 3111\n",
    "\n",
    "# User-configurable settings\n",
    "now = datetime.now()\n",
    "data_dir = \"../data/interim\"\n",
    "state_crs = crs_vic\n",
    "input_dir = \"../data/raw/climate_data\"\n",
    "output_dir = os.path.join(data_dir, f\"ricraf_fuse_data_s2\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "road_file = f\"{data_dir}/ricraf_fuse_data_s1p2/gdf_vol_rd_pav.geojson\"\n",
    "\n",
    "# Define road columns to keep\n",
    "cols_road = [\n",
    "    'OBJECTID_1', 'HMGNS_LN_1', 'LGA_SHORT_', 'RGN_LONG_N', 'ROAD_NBR',\n",
    "    'DECLARED_R', 'LOCAL_ROAD', 'RMA_CLSFCN', 'SRNS_CD', 'ALLVEHS_AA', 'TRUCKS_AAD',\n",
    "    'SEAL_WIDTH', 'Surface_Ty', 'HATI_Categ', 'Texture__L', 'Texture__B',\n",
    "    'FLOW', 'Roughness_', 'Rutting_Ca', 'Cracking_C', 'geometry'\n",
    "]\n",
    "\n",
    "# Load road dataset\n",
    "gdf_road = gpd.read_file(road_file)[cols_road].to_crs(epsg=state_crs)\n",
    "print(f\"Number of records in road dataset: {len(gdf_road)}\")\n",
    "\n",
    "# Define climate datasets and target columns\n",
    "climate_variables = {\n",
    "    f\"{input_dir}/extreme_rainfall_aus_rx5d_gwl-current_250316_vic.json\": 'rx5d_gwl-current',\n",
    "    f\"{input_dir}/extreme_temperature_aus_tn02_gwl-current_250316_vic.json\": \"tn02_gwl-current\",\n",
    "    f\"{input_dir}/extreme_temperature_aus_tx40_gwl-current_250316_vic.json\":\"tx40_gwl-current\",\n",
    "    f\"{input_dir}/temperature_aus_tgm_max_gwl-current_250317_vic.json\": \"tgm_max_gwl-current\",\n",
    "    f\"{input_dir}/temperature_aus_tgm_min_gwl-current_250317_vic.json\": \"tgm_min_gwl-current\",\n",
    "    f\"{input_dir}/drought_aridity_aus_spi3_gwl-current_250316_vic.json\": \"spi3_gwl-current\",\n",
    "    f\"{input_dir}/extreme_rainfall_aus_rx5d_gwl-1.5_250316_vic.json\": 'rx5d_gwl-1.5',\n",
    "    f\"{input_dir}/extreme_temperature_aus_tn02_gwl-1.5_250316_vic.json\": \"tn02_gwl-1.5\",\n",
    "    f\"{input_dir}/extreme_temperature_aus_tx40_gwl-1.5_250316_vic.json\":\"tx40_gwl-1.5\",\n",
    "    f\"{input_dir}/temperature_aus_tgm_max_gwl-1.5_250317_vic.json\": \"tgm_max_gwl-1.5\",\n",
    "    f\"{input_dir}/temperature_aus_tgm_min_gwl-1.5_250317_vic.json\": \"tgm_min_gwl-1.5\",\n",
    "    f\"{input_dir}/drought_aridity_aus_spi3_gwl-1.5_250316_vic.json\": \"spi3_gwl-1.5\",\n",
    "    f\"{input_dir}/extreme_rainfall_aus_rx5d_gwl-2_250316_vic.json\": 'rx5d_gwl-2.0',\n",
    "    f\"{input_dir}/extreme_temperature_aus_tn02_gwl-2_250316_vic.json\": \"tn02_gwl-2.0\",\n",
    "    f\"{input_dir}/extreme_temperature_aus_tx40_gwl-2_250316_vic.json\":\"tx40_gwl-2.0\",\n",
    "    f\"{input_dir}/temperature_aus_tgm_max_gwl-2_250317_vic.json\": \"tgm_max_gwl-2.0\",\n",
    "    f\"{input_dir}/temperature_aus_tgm_min_gwl-2_250317_vic.json\": \"tgm_min_gwl-2.0\",\n",
    "    f\"{input_dir}/drought_aridity_aus_spi3_gwl-2_250316_vic.json\": \"spi3_gwl-2.0\",\n",
    "    f\"{input_dir}/extreme_rainfall_aus_rx5d_gwl-3_250316_vic.json\": 'rx5d_gwl-3.0',\n",
    "    f\"{input_dir}/extreme_temperature_aus_tn02_gwl-3_250316_vic.json\": \"tn02_gwl-3.0\",\n",
    "    f\"{input_dir}/extreme_temperature_aus_tx40_gwl-3_250316_vic.json\":\"tx40_gwl-3.0\",\n",
    "    f\"{input_dir}/temperature_aus_tgm_max_gwl-3_250317_vic.json\": \"tgm_max_gwl-3.0\",\n",
    "    f\"{input_dir}/temperature_aus_tgm_min_gwl-3_250317_vic.json\": \"tgm_min_gwl-3.0\",\n",
    "    f\"{input_dir}/drought_aridity_aus_spi3_gwl-3_250316_vic.json\": \"spi3_gwl-3.0\",\n",
    "}\n",
    "\n",
    "# Process and merge\n",
    "try:\n",
    "    climate_columns_added = 0\n",
    "    for climate_file, target_col in climate_variables.items():\n",
    "        print(f\"\\nProcessing {climate_file}\")\n",
    "        gdf_clim = gpd.read_file(climate_file).to_crs(epsg=state_crs)\n",
    "        gdf_road = merge_road_climate(gdf_road, gdf_clim, target_col)\n",
    "        climate_columns_added += 1\n",
    "\n",
    "    gdf_road_clim = gpd.GeoDataFrame(gdf_road, geometry=gdf_road.geometry, crs=state_crs)\n",
    "    print(f\"\\nNumber of records after all merges: {len(gdf_road_clim)}\")\n",
    "    print(f\"Total climate columns added: {climate_columns_added}\")\n",
    "\n",
    "    climate_cols = list(climate_variables.values())\n",
    "    null_counts = gdf_road_clim[climate_cols].isna().sum()\n",
    "    print(\"\\nNull counts in climate columns:\")\n",
    "    print(null_counts)\n",
    "    if null_counts.sum() > 0:\n",
    "        print(\"Warning: Some climate columns contain null values.\")\n",
    "    else:\n",
    "        print(\"All climate columns are fully populated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during merge: {str(e)}\")\n",
    "\n",
    "# Save results\n",
    "if 'gdf_road_clim' in locals():\n",
    "    output_file = os.path.join(output_dir, \"gdf_road_clim.geojson\")\n",
    "    gdf_road_clim.to_file(output_file, driver='GeoJSON')\n",
    "    print(f\"\\nFused dataset saved to {output_file}\")\n",
    "    gdf_road_clim_cln = gdf_road_clim.dropna(how=\"any\")\n",
    "    output_file_cln = os.path.join(output_dir, \"gdf_road_clim_cln.geojson\")\n",
    "    gdf_road_clim_cln.to_file(output_file_cln, driver='GeoJSON')\n",
    "    print(f\"Cleaned dataset saved to {output_file_cln}\")"
   ],
   "id": "b143153b1c905e01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in road dataset: 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_rainfall_aus_rx5d_gwl-current_250316_vic.json\n",
      "Mapping 'rx5d_gwl-c' to 'rx5d_gwl-current'\n",
      "Number of non-null records for 'rx5d_gwl-current': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_temperature_aus_tn02_gwl-current_250316_vic.json\n",
      "Mapping 'tn02_gwl-c' to 'tn02_gwl-current'\n",
      "Number of non-null records for 'tn02_gwl-current': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_temperature_aus_tx40_gwl-current_250316_vic.json\n",
      "Mapping 'tx40_gwl-c' to 'tx40_gwl-current'\n",
      "Number of non-null records for 'tx40_gwl-current': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/temperature_aus_tgm_max_gwl-current_250317_vic.json\n",
      "Mapping 'tgm_max_gw' to 'tgm_max_gwl-current'\n",
      "Number of non-null records for 'tgm_max_gwl-current': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/temperature_aus_tgm_min_gwl-current_250317_vic.json\n",
      "Mapping 'tgm_min_gw' to 'tgm_min_gwl-current'\n",
      "Number of non-null records for 'tgm_min_gwl-current': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/drought_aridity_aus_spi3_gwl-current_250316_vic.json\n",
      "Mapping 'spi3_gwl-c' to 'spi3_gwl-current'\n",
      "Number of non-null records for 'spi3_gwl-current': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_rainfall_aus_rx5d_gwl-1.5_250316_vic.json\n",
      "Mapping 'rx5d_gwl-1' to 'rx5d_gwl-1.5'\n",
      "Number of non-null records for 'rx5d_gwl-1.5': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_temperature_aus_tn02_gwl-1.5_250316_vic.json\n",
      "Mapping 'tn02_gwl-1' to 'tn02_gwl-1.5'\n",
      "Number of non-null records for 'tn02_gwl-1.5': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_temperature_aus_tx40_gwl-1.5_250316_vic.json\n",
      "Mapping 'tx40_gwl-1' to 'tx40_gwl-1.5'\n",
      "Number of non-null records for 'tx40_gwl-1.5': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/temperature_aus_tgm_max_gwl-1.5_250317_vic.json\n",
      "Mapping 'tgm_max_gw' to 'tgm_max_gwl-1.5'\n",
      "Number of non-null records for 'tgm_max_gwl-1.5': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/temperature_aus_tgm_min_gwl-1.5_250317_vic.json\n",
      "Mapping 'tgm_min_gw' to 'tgm_min_gwl-1.5'\n",
      "Number of non-null records for 'tgm_min_gwl-1.5': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/drought_aridity_aus_spi3_gwl-1.5_250316_vic.json\n",
      "Mapping 'spi3_gwl-1' to 'spi3_gwl-1.5'\n",
      "Number of non-null records for 'spi3_gwl-1.5': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_rainfall_aus_rx5d_gwl-2_250316_vic.json\n",
      "Mapping 'rx5d_gwl-2' to 'rx5d_gwl-2.0'\n",
      "Number of non-null records for 'rx5d_gwl-2.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_temperature_aus_tn02_gwl-2_250316_vic.json\n",
      "Mapping 'tn02_gwl-2' to 'tn02_gwl-2.0'\n",
      "Number of non-null records for 'tn02_gwl-2.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_temperature_aus_tx40_gwl-2_250316_vic.json\n",
      "Mapping 'tx40_gwl-2' to 'tx40_gwl-2.0'\n",
      "Number of non-null records for 'tx40_gwl-2.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/temperature_aus_tgm_max_gwl-2_250317_vic.json\n",
      "Mapping 'tgm_max_gw' to 'tgm_max_gwl-2.0'\n",
      "Number of non-null records for 'tgm_max_gwl-2.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/temperature_aus_tgm_min_gwl-2_250317_vic.json\n",
      "Mapping 'tgm_min_gw' to 'tgm_min_gwl-2.0'\n",
      "Number of non-null records for 'tgm_min_gwl-2.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/drought_aridity_aus_spi3_gwl-2_250316_vic.json\n",
      "Mapping 'spi3_gwl-2' to 'spi3_gwl-2.0'\n",
      "Number of non-null records for 'spi3_gwl-2.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_rainfall_aus_rx5d_gwl-3_250316_vic.json\n",
      "Mapping 'rx5d_gwl-3' to 'rx5d_gwl-3.0'\n",
      "Number of non-null records for 'rx5d_gwl-3.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_temperature_aus_tn02_gwl-3_250316_vic.json\n",
      "Mapping 'tn02_gwl-3' to 'tn02_gwl-3.0'\n",
      "Number of non-null records for 'tn02_gwl-3.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/extreme_temperature_aus_tx40_gwl-3_250316_vic.json\n",
      "Mapping 'tx40_gwl-3' to 'tx40_gwl-3.0'\n",
      "Number of non-null records for 'tx40_gwl-3.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/temperature_aus_tgm_max_gwl-3_250317_vic.json\n",
      "Mapping 'tgm_max_gw' to 'tgm_max_gwl-3.0'\n",
      "Number of non-null records for 'tgm_max_gwl-3.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/temperature_aus_tgm_min_gwl-3_250317_vic.json\n",
      "Mapping 'tgm_min_gw' to 'tgm_min_gwl-3.0'\n",
      "Number of non-null records for 'tgm_min_gwl-3.0': 14647\n",
      "\n",
      "Processing ../data/raw/climate_data/drought_aridity_aus_spi3_gwl-3_250316_vic.json\n",
      "Mapping 'spi3_gwl-3' to 'spi3_gwl-3.0'\n",
      "Number of non-null records for 'spi3_gwl-3.0': 14647\n",
      "\n",
      "Number of records after all merges: 14647\n",
      "Total climate columns added: 24\n",
      "\n",
      "Null counts in climate columns:\n",
      "rx5d_gwl-current       0\n",
      "tn02_gwl-current       0\n",
      "tx40_gwl-current       0\n",
      "tgm_max_gwl-current    0\n",
      "tgm_min_gwl-current    0\n",
      "spi3_gwl-current       0\n",
      "rx5d_gwl-1.5           0\n",
      "tn02_gwl-1.5           0\n",
      "tx40_gwl-1.5           0\n",
      "tgm_max_gwl-1.5        0\n",
      "tgm_min_gwl-1.5        0\n",
      "spi3_gwl-1.5           0\n",
      "rx5d_gwl-2.0           0\n",
      "tn02_gwl-2.0           0\n",
      "tx40_gwl-2.0           0\n",
      "tgm_max_gwl-2.0        0\n",
      "tgm_min_gwl-2.0        0\n",
      "spi3_gwl-2.0           0\n",
      "rx5d_gwl-3.0           0\n",
      "tn02_gwl-3.0           0\n",
      "tx40_gwl-3.0           0\n",
      "tgm_max_gwl-3.0        0\n",
      "tgm_min_gwl-3.0        0\n",
      "spi3_gwl-3.0           0\n",
      "dtype: int64\n",
      "All climate columns are fully populated.\n",
      "\n",
      "Fused dataset saved to ../data/interim\\ricraf_fuse_data_s2\\gdf_road_clim.geojson\n",
      "Cleaned dataset saved to ../data/interim\\ricraf_fuse_data_s2\\gdf_road_clim_cln.geojson\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Final Data Cleaning and Preparation\n",
    "\n",
    "This stage performs final cleaning, imputation, and feature engineering on the fused dataset.\n",
    "\n",
    "**Key Steps:**\n",
    "- Map categorical values (e.g. surface types to descriptive labels).\n",
    "- Impute zero values in temperature columns using nearest neighbors.\n",
    "- Compute additional features (e.g. link length, non-truck AADT).\n",
    "- Generate unique road link IDs.\n",
    "- Drop remaining nulls and save the final dataset.\n",
    "\n",
    "The final output is `gdf_road_clim_cln.geojson` in `../data/processed/`.\n"
   ],
   "id": "2783225b3bf212d5"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:51:28.563330Z",
     "start_time": "2025-10-19T14:49:20.409670Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load fused road-climate dataset\n",
    "gdf = gpd.read_file(\"../data/interim/ricraf_fuse_data_s2/gdf_road_clim_cln.geojson\")\n",
    "print(f\"Initial dataset size: {len(gdf)} road links\")\n",
    "\n",
    "# Map surface types\n",
    "surface_type_mapping = {\n",
    "    'S': 'Stone Seal', 'A': 'Asphalt', 'U': 'Ultra Thin Asphalt',\n",
    "    'C': 'Concrete', 'H': 'High Friction Surface Treatment',\n",
    "    'G': 'Gravel', 'X': 'Other'\n",
    "}\n",
    "print(\"Before mapping:\", gdf['Surface_Ty'].unique())\n",
    "gdf['Surface_Ty'] = gdf['Surface_Ty'].replace(surface_type_mapping)\n",
    "print(\"After mapping:\", gdf['Surface_Ty'].unique())\n",
    "\n",
    "# Compute link length\n",
    "gdf['link_length'] = gdf['geometry'].length\n",
    "\n",
    "# Impute zero values in GWL temperature columns using nearest neighbor\n",
    "gwl_columns = [\n",
    "    'tx40_gwl-current', 'tx40_gwl-1.5', 'tx40_gwl-2.0', 'tx40_gwl-3.0'\n",
    "]\n",
    "for col in gwl_columns:\n",
    "    zero_links = gdf[gdf[col] == 0]\n",
    "    print(f\"Before imputation for {col}=0: {len(zero_links)} road links\")\n",
    "    zero_indices = zero_links.index.tolist()\n",
    "    for idx in zero_indices:\n",
    "        current_geom = gdf.loc[idx, 'geometry']\n",
    "        non_zero_links = gdf[gdf[col] > 0].copy()\n",
    "        if not non_zero_links.empty:\n",
    "            non_zero_links['distance'] = non_zero_links['geometry'].apply(lambda x: current_geom.distance(x))\n",
    "            closest_link = non_zero_links.loc[non_zero_links['distance'].idxmin()]\n",
    "            gdf.loc[idx, col] = closest_link[col]\n",
    "    remaining_zero_links = gdf[gdf[col] == 0]\n",
    "    print(f\"After imputation for {col}=0: {len(remaining_zero_links)} road links\")\n",
    "\n",
    "# # Optional EDA: Histogram of imputed temperature values (uncomment to plot)\n",
    "# import matplotlib.pyplot as plt\n",
    "# for col in gwl_columns:\n",
    "#     plt.figure()\n",
    "#     gdf[col].hist(bins=20)\n",
    "#     plt.title(f\"Distribution of {col}\")\n",
    "#     plt.xlabel(f\"{col} - No. of Days\")\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.show()\n",
    "\n",
    "# Compute non-truck AADT\n",
    "gdf['NON_TRUCKS_AADT'] = gdf['ALLVEHS_AA'] - gdf['TRUCKS_AAD']\n",
    "\n",
    "# Generate unique road link IDs\n",
    "gdf['Segment_Index'] = gdf.groupby('OBJECTID_1').cumcount() + 1\n",
    "gdf['road_link_id'] = gdf['OBJECTID_1'].astype(str) + '_' + gdf['Segment_Index'].astype(str)\n",
    "gdf = gdf.drop(columns=['Segment_Index'])\n",
    "if gdf['road_link_id'].is_unique:\n",
    "    print(\"road_link_id is unique.\")\n",
    "else:\n",
    "    print(\"Warning: road_link_id is not unique.\")\n",
    "\n",
    "# Final drop of nulls\n",
    "gdf = gdf.dropna(how='any')\n",
    "print(f\"Final dataset size after dropping nulls: {len(gdf)} road links\")\n",
    "\n",
    "# Save final dataset\n",
    "fn_gdf_road_clim = \"gdf_road_clim_cln_final_withfuture.geojson\"\n",
    "gdf.to_file(f\"../data/processed/{fn_gdf_road_clim}\", driver='GeoJSON')\n",
    "print(f\"Final dataset saved to '../data/processed/{fn_gdf_road_clim}'.\")\n",
    "\n",
    "# Save to CSV\n",
    "df = gdf.drop(columns=['geometry'], errors='ignore')\n",
    "csv_output_path = f\"../data/processed/{fn_gdf_road_clim}.csv\"\n",
    "df.to_csv(csv_output_path, index=False)\n",
    "print(f\"Final dataset as CSV to '{csv_output_path}'.\")\n"
   ],
   "id": "86fdc32bc8a040b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: 7579 road links\n",
      "Before mapping: ['S' 'A' 'C' 'U' 'H' 'G' 'X']\n",
      "After mapping: ['Stone Seal' 'Asphalt' 'Concrete' 'Ultra Thin Asphalt'\n",
      " 'High Friction Surface Treatment' 'Gravel' 'Other']\n",
      "Before imputation for tx40_gwl-current=0: 248 road links\n",
      "After imputation for tx40_gwl-current=0: 0 road links\n",
      "Before imputation for tx40_gwl-1.5=0: 239 road links\n",
      "After imputation for tx40_gwl-1.5=0: 0 road links\n",
      "Before imputation for tx40_gwl-2.0=0: 238 road links\n",
      "After imputation for tx40_gwl-2.0=0: 0 road links\n",
      "Before imputation for tx40_gwl-3.0=0: 232 road links\n",
      "After imputation for tx40_gwl-3.0=0: 0 road links\n",
      "road_link_id is unique.\n",
      "Final dataset size after dropping nulls: 7579 road links\n",
      "Final dataset saved to '../data/processed/gdf_road_clim_cln_final_withfuture.geojson'.\n",
      "Final dataset as CSV to '../data/processed/gdf_road_clim_cln_final_withfuture.geojson.csv'.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Validation",
   "id": "f9c0b01a16151ac4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:51:32.282895Z",
     "start_time": "2025-10-19T14:51:28.773998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.validation import explain_validity\n",
    "\n",
    "# Load final dataset\n",
    "gdf = gpd.read_file(\"../data/processed/gdf_road_clim_cln_final_withfuture.geojson\")\n",
    "\n",
    "# 1. Topology Validation: Check invalid geometries\n",
    "invalid_geoms = gdf[~gdf.geometry.is_valid].copy()\n",
    "invalid_geoms['invalid_reason'] = invalid_geoms.geometry.apply(explain_validity)\n",
    "print(f\"Invalid geometries: {len(invalid_geoms)}\")\n",
    "if not invalid_geoms.empty:\n",
    "    invalid_geoms.to_file(\"../data/processed/invalid_geometries.geojson\", driver='GeoJSON')\n",
    "\n",
    "# 2. Statistical Summaries: Describe key variables\n",
    "summary = gdf.describe(include='all')\n",
    "summary.to_csv(\"../data/processed/dataset_summary.csv\")\n",
    "print(f\"Dataset summary saved to '../data/processed/dataset_summary.csv'.\")\n",
    "# print(\"Dataset Summary:\\n\", summary)\n",
    "\n",
    "# 3. Cross-Validation: Sample comparison with raw sources (example for rx5d_gwl-current)\n",
    "raw_climate_rx5d = gpd.read_file(\"../data/raw/climate_data/extreme_rainfall_aus_rx5d_gwl-current_250316_vic.json\")\n",
    "# For 100 random samples, compute MAE\n",
    "samples = gdf.sample(100)\n",
    "mae_values = []\n",
    "for idx, row in samples.iterrows():\n",
    "    raw_value = raw_climate_rx5d.loc[raw_climate_rx5d.intersects(row.geometry), 'rx5d_gwl-c'].mean()\n",
    "    fused_value = row['rx5d_gwl-current']\n",
    "    if not np.isnan(raw_value):\n",
    "        mae_values.append(abs(raw_value - fused_value))\n",
    "mae = np.mean(mae_values)\n",
    "print(f\"Mean Absolute Error for rx5d_current (sample): {mae:.2f} mm\")\n",
    "\n",
    "# 4. Null and Range Checks\n",
    "null_counts = gdf.isnull().sum()\n",
    "out_of_range = gdf[(gdf['ALLVEHS_AA'] < 0) | (gdf['tx40_gwl-current'] < 0)]  # Example ranges\n",
    "print(\"Null Counts:\\n\", null_counts)\n",
    "print(f\"Out-of-range records: {len(out_of_range)}\")\n"
   ],
   "id": "19584bb4b4699db5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid geometries: 0\n",
      "Dataset summary saved to '../data/processed/dataset_summary.csv'.\n",
      "Mean Absolute Error for rx5d_current (sample): 0.00 mm\n",
      "Null Counts:\n",
      " OBJECTID_1             0\n",
      "HMGNS_LN_1             0\n",
      "LGA_SHORT_             0\n",
      "RGN_LONG_N             0\n",
      "ROAD_NBR               0\n",
      "DECLARED_R             0\n",
      "LOCAL_ROAD             0\n",
      "RMA_CLSFCN             0\n",
      "SRNS_CD                0\n",
      "ALLVEHS_AA             0\n",
      "TRUCKS_AAD             0\n",
      "SEAL_WIDTH             0\n",
      "Surface_Ty             0\n",
      "HATI_Categ             0\n",
      "Texture__L             0\n",
      "Texture__B             0\n",
      "FLOW                   0\n",
      "Roughness_             0\n",
      "Rutting_Ca             0\n",
      "Cracking_C             0\n",
      "rx5d_gwl-current       0\n",
      "tn02_gwl-current       0\n",
      "tx40_gwl-current       0\n",
      "tgm_max_gwl-current    0\n",
      "tgm_min_gwl-current    0\n",
      "spi3_gwl-current       0\n",
      "rx5d_gwl-1.5           0\n",
      "tn02_gwl-1.5           0\n",
      "tx40_gwl-1.5           0\n",
      "tgm_max_gwl-1.5        0\n",
      "tgm_min_gwl-1.5        0\n",
      "spi3_gwl-1.5           0\n",
      "rx5d_gwl-2.0           0\n",
      "tn02_gwl-2.0           0\n",
      "tx40_gwl-2.0           0\n",
      "tgm_max_gwl-2.0        0\n",
      "tgm_min_gwl-2.0        0\n",
      "spi3_gwl-2.0           0\n",
      "rx5d_gwl-3.0           0\n",
      "tn02_gwl-3.0           0\n",
      "tx40_gwl-3.0           0\n",
      "tgm_max_gwl-3.0        0\n",
      "tgm_min_gwl-3.0        0\n",
      "spi3_gwl-3.0           0\n",
      "link_length            0\n",
      "NON_TRUCKS_AADT        0\n",
      "road_link_id           0\n",
      "geometry               0\n",
      "dtype: int64\n",
      "Out-of-range records: 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Citation and License\n",
    "\n",
    "If using this dataset or code, please cite:\n",
    "- Chin, T. K., et al. (2025). Processing and Fusion of Open-Source Road and Climate Data for Victoria, Australia. *Earth System Science Data*, [DOI or Volume/Issue].\n",
    "- Code: Chin, T. K. (2025). RICRAF GitHub Repository. DOI: [Zenodo DOI, e.g., 10.5281/zenodo.XXXXXXX].\n",
    "\n",
    "**License:** MIT (see LICENSE file in repository)."
   ],
   "id": "67d0c20e0337747a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "- Geopandas Documentation: https://geopandas.org/\n",
    "- DataVic Road Data: https://www.data.vic.gov.au/\n",
    "- Australian Climate Service: https://www.acs.gov.au/\n",
    "\n",
    "\n"
   ],
   "id": "cb295fdfb2ea2666"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:51:32.289846Z",
     "start_time": "2025-10-19T14:51:32.286911Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "21aa95ed399e4948",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:51:32.418329Z",
     "start_time": "2025-10-19T14:51:32.413710Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c9e422496a39cef1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
